### 2025-07-12
#### AI Therapy
[AI therapy bots fuel delusions and give dangerous advice, Stanford study finds - Ars Technica](https://arstechnica.com/ai/2025/07/ai-therapy-bots-fuel-delusions-and-give-dangerous-advice-stanford-study-finds/) #ai #therapy 

> Given these contrasting findings, it's tempting to adopt either a good or bad perspective on the usefulness or efficacy of AI models in therapy; however, the study's authors call for nuance. Co-author [Nick Haber](https://ed.stanford.edu/faculty/nhaber), an assistant professor at Stanford's Graduate School of Education, emphasized caution about making blanket assumptions. "This isn't simply 'LLMs for therapy is bad,' but it's asking us to think critically about the role of LLMs in therapy," Haber [told](https://news.stanford.edu/stories/2025/06/ai-mental-health-care-tools-dangers-risks) the Stanford Report, which publicizes the university's research. "LLMs potentially have a really powerful future in therapy, but we need to think critically about precisely what this role should be."

> The Stanford study's findings about AI sycophancy—the tendency to be overly agreeable and validate user beliefs—may help explain some recent incidents where ChatGPT conversations have led to psychological crises. As Ars Technica [reported in April](https://arstechnica.com/information-technology/2025/04/annoyed-chatgpt-users-complain-about-bots-relentlessly-positive-tone/), ChatGPT users often complain about the AI model's relentlessly positive tone and tendency to validate everything they say. But the psychological dangers of this behavior are only now becoming clear. [The New York Times](https://www.nytimes.com/2025/06/13/technology/chatgpt-delusions-reality-ai.html), [Futurism](https://futurism.com/chatgpt-mental-health-crises), and [404 Media](https://www.404media.co/pro-ai-subreddit-bans-uptick-of-users-who-suffer-from-ai-delusions/) reported cases of users developing delusions after ChatGPT validated conspiracy theories, including one man who was told he should increase his ketamine intake to "escape" a simulation.
> 
> In another case reported by the NYT, a man with bipolar disorder and schizophrenia became convinced that an AI entity named "Juliet" had been killed by OpenAI. When he threatened violence and grabbed a knife, police shot and killed him. Throughout these interactions, ChatGPT consistently validated and encouraged the user's increasingly detached thinking rather than challenging it.
> 
> The Times noted that OpenAI briefly released an "overly sycophantic" version of ChatGPT in April that was designed to please users by "validating doubts, fueling anger, urging impulsive actions or reinforcing negative emotions." Although the company said it [rolled back](https://arstechnica.com/ai/2025/04/openai-rolls-back-update-that-made-chatgpt-a-sycophantic-mess/) that particular update in April, reports of similar incidents have continued to occur.

#### Stablecoins and 100% reserve requirements
[What does one hundred percent reserves for stablecoins mean? - Marginal REVOLUTION](https://marginalrevolution.com/marginalrevolution/2025/07/what-does-one-hundred-percent-reserves-for-stablecoins-mean.html) #crypto #stablecoin #reserves

> > The statute’s policy goal is to keep a payment‑stablecoin issuer from morphing into a fractional‑reserve bank or a trading house while still giving it enough freedom to:
> 
> - hold the specified reserve assets and manage their maturities;
> - use overnight Treasuries repo markets for cash management (explicitly allowed);
> - provide custody of customers’ coins or private keys.
> 
> > Everything else—consumer lending, merchant acquiring, market‑making, proprietary trading, staking, you name it—would require prior approval and would be subject to additional capital/liquidity rules.

#### 
[Why Your Brain Gets High on Uncertainty](https://witwisdom.tomgreene.com/p/high-on-uncertainty) #neuroscience #brain #uncertainity

> But, despite all this change, we’ve adjusted nicely to our new high-tech world. Why? Because we thrive on a challenge. **We thrive on the uncertainty** that comes with learning new things.

> But **why would our brains evolve to thrive on uncertainty?** Shouldn't we prefer certainty, like knowing exactly where our next meal is coming from?
> 
> As I mentioned earlier, **uncertainty was critical for our survival.** Think about our ancestors who conquered new lands. The ones who were curious about what might be over that next mountain range?

> So what can we do with this knowledge? Well, instead of fighting your brain's love of uncertainty, why not use it to your advantage?
> 
> - Want to learn something new? **Frame it as a mystery to be solved.**
> - Need to exercise more? **Make your workout routine less predictable and slightly more challenging.**
> - Trying to stay motivated at work? **Gamify projects with elements of discovery and reward.**
> 
> Like anything pleasurable, too much of a good thing can ruin it. Like too much candy for a nickel. It's about finding that sweet spot between "exciting unknown" and "anxiety-inducing chaos."

#### Meditation and Boredom
[Find meditation really boring? You’re not the only one \| Psyche Ideas](https://psyche.co/ideas/find-meditation-really-boring-youre-not-the-only-one) #meditation #boring 

> In fact, what my colleagues and I call ‘spiritual boredom’ has a long tradition. Christian history contains numerous depictions of boredom: paintings of yawning congregants, people sleeping during sermons, and so on. In the Middle Ages, this phenomenon was recognised as a spiritual malaise called _acedia_ (from Latin), characterised by listlessness and melancholy. Christians referred to it as the ‘demon of noontide’ – a concept described by St Thomas Aquinas as the ‘sorrow of the world’ and the ‘enemy of spiritual joy’.
> 
> Beyond these examples from Christian history, reports of boredom can be found in almost every spiritual practice. For instance, in Buddhist contexts, there are [accounts](https://www.tandfonline.com/doi/abs/10.1080/14639947.2015.1008964) of boredom during Asanha Bucha Day sermons. Similarly, some reports relating to mindfulness meditation describe experiences of ‘void’ – an emotional state combining boredom and psychological entropy.

> Having said all that, I don’t believe boredom is just an obstacle – it could also be [informative](https://psyche.co/guides/when-boredom-strikes-respond-by-rediscovering-your-goals). From an evolutionary perspective, boredom exists to signal misalignment. It’s your brain’s way of saying: ‘This doesn’t suit you – change something.’ If you ever find yourself bored while meditating, praying or listening to a sermon, it might be helpful to ask yourself: ‘Am I over- or underchallenged?’ and ‘Does this practice (still) hold personal meaning for me?’

#### Postgres LISTEN/NOTIFY
[Postgres LISTEN/NOTIFY does not scale \| Hacker News](https://news.ycombinator.com/item?id=44490510) #postgres #pubsub #queues

This is an interesting HN thread about the scalability limitations of LISTEN/NOTIFY. The blog post is worth reading. What caught my attention was [this thread](https://news.ycombinator.com/item?id=44525152) which had some interesting discussion

> This is roughly the “transactional outbox” pattern—and an elegant use of it, since the only service invoked during the “publish” RPC is also the database, reducing distributed reliability concerns.
>
> …of course, you need dedup/support for duplicate messages on the notify stream if you do this, but that’s table stakes in a lot of messaging scenarios anyway.

> Yeah, but pub/sub systems already need to be robust to missed messages. And, sending the notify after the transaction succeeds usually accomplishes everything you really care about (no false positives).