### 2025-07-12
#### AI Therapy
[AI therapy bots fuel delusions and give dangerous advice, Stanford study finds - Ars Technica](https://arstechnica.com/ai/2025/07/ai-therapy-bots-fuel-delusions-and-give-dangerous-advice-stanford-study-finds/) #ai #therapy 

> Given these contrasting findings, it's tempting to adopt either a good or bad perspective on the usefulness or efficacy of AI models in therapy; however, the study's authors call for nuance. Co-author [Nick Haber](https://ed.stanford.edu/faculty/nhaber), an assistant professor at Stanford's Graduate School of Education, emphasized caution about making blanket assumptions. "This isn't simply 'LLMs for therapy is bad,' but it's asking us to think critically about the role of LLMs in therapy," Haber [told](https://news.stanford.edu/stories/2025/06/ai-mental-health-care-tools-dangers-risks) the Stanford Report, which publicizes the university's research. "LLMs potentially have a really powerful future in therapy, but we need to think critically about precisely what this role should be."

> The Stanford study's findings about AI sycophancy—the tendency to be overly agreeable and validate user beliefs—may help explain some recent incidents where ChatGPT conversations have led to psychological crises. As Ars Technica [reported in April](https://arstechnica.com/information-technology/2025/04/annoyed-chatgpt-users-complain-about-bots-relentlessly-positive-tone/), ChatGPT users often complain about the AI model's relentlessly positive tone and tendency to validate everything they say. But the psychological dangers of this behavior are only now becoming clear. [The New York Times](https://www.nytimes.com/2025/06/13/technology/chatgpt-delusions-reality-ai.html), [Futurism](https://futurism.com/chatgpt-mental-health-crises), and [404 Media](https://www.404media.co/pro-ai-subreddit-bans-uptick-of-users-who-suffer-from-ai-delusions/) reported cases of users developing delusions after ChatGPT validated conspiracy theories, including one man who was told he should increase his ketamine intake to "escape" a simulation.
> 
> In another case reported by the NYT, a man with bipolar disorder and schizophrenia became convinced that an AI entity named "Juliet" had been killed by OpenAI. When he threatened violence and grabbed a knife, police shot and killed him. Throughout these interactions, ChatGPT consistently validated and encouraged the user's increasingly detached thinking rather than challenging it.
> 
> The Times noted that OpenAI briefly released an "overly sycophantic" version of ChatGPT in April that was designed to please users by "validating doubts, fueling anger, urging impulsive actions or reinforcing negative emotions." Although the company said it [rolled back](https://arstechnica.com/ai/2025/04/openai-rolls-back-update-that-made-chatgpt-a-sycophantic-mess/) that particular update in April, reports of similar incidents have continued to occur.

#### Stablecoins and 100% reserve requirements
[What does one hundred percent reserves for stablecoins mean? - Marginal REVOLUTION](https://marginalrevolution.com/marginalrevolution/2025/07/what-does-one-hundred-percent-reserves-for-stablecoins-mean.html) #crypto #stablecoin #reserves

> > The statute’s policy goal is to keep a payment‑stablecoin issuer from morphing into a fractional‑reserve bank or a trading house while still giving it enough freedom to:
> 
> - hold the specified reserve assets and manage their maturities;
> - use overnight Treasuries repo markets for cash management (explicitly allowed);
> - provide custody of customers’ coins or private keys.
> 
> > Everything else—consumer lending, merchant acquiring, market‑making, proprietary trading, staking, you name it—would require prior approval and would be subject to additional capital/liquidity rules.

#### 
[Why Your Brain Gets High on Uncertainty](https://witwisdom.tomgreene.com/p/high-on-uncertainty) #neuroscience #brain #uncertainity

> So what can we do with this knowledge? Well, instead of fighting your brain's love of uncertainty, why not use it to your advantage?
> 
> - Want to learn something new? **Frame it as a mystery to be solved.**
> - Need to exercise more? **Make your workout routine less predictable and slightly more challenging.**
> - Trying to stay motivated at work? **Gamify projects with elements of discovery and reward.**
> 
> Like anything pleasurable, too much of a good thing can ruin it. Like too much candy for a nickel. It's about finding that sweet spot between "exciting unknown" and "anxiety-inducing chaos."