### 2025-01-28
#### Deepseek
Karen Hao has an excellent Twitter thread on an alternative paradigm of moving AI forward.

![](https://x.com/_KarenHao/status/1883877986656825503)

[DeepSeek FAQ – Stratechery by Ben Thompson](https://stratechery.com/2025/deepseek-faq/)

> Here’s the thing: a huge number of the innovations I explained above are about overcoming the lack of memory bandwidth implied in using H800s instead of H100s. Moreover, if you actually did the math on the previous question, you would realize that DeepSeek actually had an excess of computing; that’s because DeepSeek actually programmed 20 of the 132 processing units on each H800 specifically to manage cross-chip communications. _This is actually impossible to do in CUDA._ DeepSeek engineers had to drop down to PTX, a low-level instruction set for Nvidia GPUs that is basically like assembly language. This is an insane level of optimization that only makes sense if you are using H800s.

There is also a bit about why this might be good for big tech, _but_ in the long run.