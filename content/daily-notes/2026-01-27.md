### 2026-01-27
#### Why software work estimations are hard
[How I estimate work as a staff software engineer](https://www.seangoedecke.com/how-i-estimate-work/) #software #estimates

Just putting it here so that the next time somebody comes along wondering about this, I can point them here.

> I’m also going to concede that **sometimes you can accurately estimate software work**, when that work is very well-understood and very small in scope. For instance, if I know it takes half an hour to deploy a service[1](https://www.seangoedecke.com/how-i-estimate-work/#fn-1), and I’m being asked to update the text in a link, I can accurately estimate the work at something like 45 minutes: five minutes to push the change up, ten minutes to wait for CI, thirty minutes to deploy.
> 
> For most of us, the majority of software work is not like this. We work on poorly-understood systems and cannot predict exactly what must be done in advance. Most programming in large systems is _research_: identifying prior art, mapping out enough of the system to understand the effects of changes, and so on. Even for fairly small changes, we simply do not know what’s involved in making the change until we go and look.
> 
> The pro-estimation dogma says that these questions ought to be answered during the planning process, so that each individual piece of work being discussed is scoped small enough to be accurately estimated. I’m not impressed by this answer. It seems to me to be a throwback to the bad old days of [software architecture](https://en.wikipedia.org/wiki/Software_architect), where one architect would map everything out in advance, so that individual programmers simply had to mechanically follow instructions. Nobody does that now, because it doesn’t work: programmers must be empowered to make architectural decisions, because they’re the ones who are actually in contact with the code[2](https://www.seangoedecke.com/how-i-estimate-work/#fn-2). Even if it did work, that would simply shift the impossible-to-estimate part of the process backwards, into the planning meeting (where of course you can’t write or run code, which makes it near-impossible to accurately answer the kind of questions involved).
> 
> In short: software engineering projects are not dominated by the known work, but by the unknown work, which always takes 90% of the time. However, only the known work can be accurately estimated. It’s therefore impossible to accurately estimate software projects in advance.


#### Intelligence and Wisdom
[Why Intelligence Is a Terrible Proxy for Wisdom](https://www.joanwestenberg.com/why-intelligence-is-a-terrible-proxy-for-wisdom/)

> Simply put: smart people, by virtue of being very fucking smart, are better at constructing post-hoc rationalizations for beliefs they hold for emotional or social reasons. Everyone does this to some extent. We form impressions and then search for evidence to support them. But intelligent people search more effectively. They find better evidence, or at least better-sounding evidence. They anticipate counterarguments and preemptively defuse them. They build fortresses of logic around conclusions they reached for entirely non-logical reasons, and those fortresses can become so elaborate and well-defended that the person living inside them never realizes they’re trapped.
> 
> Philip Tetlock’s research on expert political judgment found that the experts with the most impressive credentials and the strongest reputations for insight performed barely better than chance at predicting geopolitical events, and sometimes performed worse than simple algorithms. The experts who performed best tended to be what Tetlock called “foxes” rather than “hedgehogs,” borrowing from Archilochus’s ancient distinction. Hedgehogs know one big thing and apply it everywhere, while foxes know many small things and adapt flexibly. The hedgehogs were frequently the most intelligent and articulate members of the sample. They also consistently overestimated their own accuracy and failed to update their beliefs when predictions went wrong.
> 
> Intelligence, it seems, can produce a particularly fraught form of intellectual pride. You’ve been right so many times before, in so many situations, in ways that others couldn’t match.


> Wisdom is _knowing what you don’t know._
> 
> Wisdom is what tells you to ignore the memecoin // prediction market bet, even though you _could_ construct an excellent narrative explaining why this time will be different. Wisdom is what tells you that your political opponents might have a point, even though you _could_ demolish their arguments in debate. Wisdom is what tells you not to install Clawdbot on your personal device and give it access to your banking details, even though you _could_ become the next Tony Stark.
> 
> Intelligence can be measured on tests.
> 
> Wisdom is a good deal harder to quantify.


#### The Age of Pump and Dump Software
[The Age of Pump and Dump Software \| by Tautvilas Mečinskas \| Jan, 2026 \| Medium](https://tautvilas.medium.com/software-pump-and-dump-c8a9a73d313b)

The usual suspects are covered here: Cursor's browser, Yegge's Gas Town project and ClawdBot (now Moldbot).

I havent used any of them, and I wont bother. Pump and Dump does seem like an apt description. There is a larger story here around how so much of software we are building - and this gets turbocharged in the age of agent assisted coding, However, something makes me pause here. 