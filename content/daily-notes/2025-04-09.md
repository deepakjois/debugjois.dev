### 2025-04-09
#### Inquiring Together
[Why not inquire together more? - Marginal REVOLUTION](https://marginalrevolution.com/marginalrevolution/2025/04/why-not-inquire-together-more.html) #inquiry #questions #discussion #ideas

> I find that “inquiring together” works best when you are traveling together, and confronted with _new_ questions.  They can be as mundane as “do you think the two people at that restaurant table are on a first date or not?”  From the point of view of the observers, the inquiry is de novo.  And the joint inquiry will be fun, and may make some progress.  You both have more or less the same starting point.  There isn’t really a better way to proceed, short of asking them.
> 
> For most established social science and philosophy questions, however, there is so much preexisting analysis and literature that the “chains of thought” are very long.  The frontier point is not well maintained by a dyadic conversation, because doing so is computationally complex and further the two individuals likely have at least marginally separate agendas.  So the pair end up talking around in circles, rather than progressively.  It would be better if one person wrote a short memo or brief and the other offered comments.  In fact we usethat method frequently, and fairly often it succeeds in keeping the dialogue at the epistemic frontier.


#### Shopify CEO Memo
![](https://x.com/tobi/status/1909231499448401946)

This memo of the Shopify CEO mandating AI usage is doing the rounds. 

The skeptic in me wonders if something that is obviously useful really needs a top-down mandate. Wouldn't developers automatically adopt it if AI was that transformational? It sounds to me like a bit of a bait and switch where the true agenda is something else - like justifying hiring less and dumping more work on the currently working engineers at Shopify, and using AI as an excuse for keeping up the same level of productivity and output.

On the other hand, this could one of those memos which goes down in technology lore as something that changed computing forever, like the famous Bezos memo: [API Mandate: How Jeff Bezos' memo changed software forever  \| Kong Inc.](https://konghq.com/blog/enterprise/api-mandate)

#### AI coding mandates are driving developers to the brink
[AI coding mandates are driving developers to the brink - LeadDev](https://leaddev.com/culture/ai-coding-mandates-are-driving-developers-to-the-brink)

This dropped a day or so after the AI memo above, and is very skeptical about AI Adoption.

> For software developers specifically, there are concerns that AI coding tools are introducing errors into their code, failing at many tasks, and [compounding technical debt](https://leaddev.com/software-quality/how-ai-generated-code-accelerates-technical-debt). But they also feel that misguided mandates are inhibiting the successful adoption of AI tools. While AI coding assistants can be helpful, it’s clear that how leaders approach and support engineering teams makes all the difference.

The [HN Discussion](https://news.ycombinator.com/item?id=43633288) around it is pretty insightful as well. From the comments:

> I think a lot of confusion and frustration about this is the assumption that all programming is the same thing.
> 
> I have seen areas with just tons of boilerplate, straight forward UI stuff, basic test skeletons, etc that I guess could work with AI.
> 
> But personally, in 30 years I’ve just never done much of that kind of work. Probably because I find it boring. I go look for hard or novel problems, or data structures and APIs that are causing problems (overgrown and hard to use, buggy, etc). A lot of the time is just figuring out what the authors expected the code to do, and anticipating what we will need for the next few years. I don’t see AI helping much with that.

> This pattern is maybe 20% about AI specifically and 80% about low-trust leadership.

> LLMs require comparatively little training to use, and in fact training (like how to optimize prompts etc.) is probably a waste of time because the model behavior and interfaces change so frequently.
>
> This puts them in the class of tools where the benefit is obvious once there is actually a real benefit (and not, say, the foreshadowing of some future benefit). This sort of tool doesn't require a mandate to gain adoption.
>
> So, in the subdomains of software development where the LLMs are already useful, developers will naturally pick them up, assuming the business has secured the policy support and funding. In the areas where they aren't useful, businesses should trust developers and not waste their time with mandates.
>
> And I say this as someone who uses LLMs all day every day for Python, Go, Bash, C/C++, pretty much everything. But as an active user I see the limitations constantly and wouldn't mandate their use upon anyone.