### 2025-06-04
#### AI is not a technology, it's an ideology
[Toolmen \| A Working Library](https://aworkinglibrary.com/writing/toolmen) #ai #ideology #technology 

> “Artificial intelligence” is not a technology. A chef’s knife is a technology, as are the practices around its use in the kitchen. A tank is a technology, as are the ways a tank is deployed in war. Both can kill, but one cannot meaningfully talk about a technology that encompasses both Sherman and santoku; the affordances, practices, and intentions are far too different to be brought into useful conversation. Likewise, in the hysterical gold rush to hoover up whatever money they can, the technocrats have labeled any and all manner of engineering practices as “AI” and riddled their products with sparkle emojis, to the extent that what we mean when we say AI is, from a technology standpoint, no longer meaningful. AI seems to be, at every moment, everything from an algorithm of the kind that has been in use for half a century, to bullshit generators that clutter up our information systems, to the promised arrival of a new consciousness—a prophesied god who will either savage us or save us or, somehow, both at the same time. There exists no coherent notion of what AI is or could be, and no meaningful effort to coalesce around a set of practices, because to do so would be to reduce the opportunity for grift.
> 
> What AI _is_ is an ideology—a system of ideas that has swept up not only the tech industry but huge parts of government on both sides of the aisle, a supermajority of everyone with assets in the millions and up, and a seemingly growing sector of the journalism class. The ideology itself is nothing new—it is the age-old system of supremacy, granting care and comfort to some while relegating others to servitude and penury—but the wrappings have been updated for the late capital, late digital age, a gaudy new cloak for today’s would-be emperors. Engaging with AI as a _technology_ is to play the fool—it’s to observe the reflective surface of the thing without taking note of the way it sends roots deep down into the ground, breaking up bedrock, poisoning the soil, reaching far and wide to capture, uproot, strangle, and steal everything within its reach. It’s to stand aboveground and pontificate about the marvels of this bright new magic, to be dazzled by all its flickering, glittering glory, its smooth mirages and six-fingered messiahs, its apparent obsequiousness in response to all your commands, right up until the point when a sinkhole opens up and swallows you whole.

#### When is Insurance Worth It
[When Is Insurance Worth It?](https://entropicthoughts.com/when-is-insurance-worth-it) #insurance #finance 

> These are the things I would say in response.
>
> - It is not a philosophical question, it is a mathematical one.
> - Technically, some insurance is worth its price, _even when_ the insurance company makes a profit.
> - Whether or not to get insurance should have nothing to do with what makes one sleep – again, it is a mathematical decision with a correct answer.
> - Saving up the premium instead of getting insurance is making the mistake of conflating an ensemble average with a time average.
> - Love does not make insurance a mathematically appropriate decision. Running the numbers does.

> The purpose if insurance is _not_ only to help us pay for things that we literally do not have enough money to pay for. It does help in that situation, but the purpose of insurance is much broader than that. What insurance does is help us avoid large drawndowns on our accumulated wealth, in order for our wealth to gather compound interest faster.
> 
> Think about that. _Even though insurance is an expected loss for the insured_, it helps us earn more money in the long run. This comes back to the [Kelly criterion](https://entropicthoughts.com/the-misunderstood-kelly-criterion.html), which teaches us that the compounding effects on wealth can make it worth paying a little up front to avoid a potential large loss later.33 The typical example is how it takes as long to go from $2,000 to $10,000 as it does from $10,000 to $50,000. This means that if we are forced to pay $8,000 out of our $10,000 wealth, we will end up with $10,000 again at the same time as we would have ended up with $50,000 if we had not been forced to pay. Losing $8,000 at one point is equal to a $40,000 loss later on, once compounding is taken into account. No wonder Einstein coined compounding the eighth wonder of the world. This effect is huge. Having to shell out 20 % of our wealth for an unexpected accident is so bad – even if the accident is improbable – that we may want to chuck out a guaranteed 0.5 % of our wealth to get out of that risk.
> 
> _This_ is the hidden purpose of insurance. It’s great at protecting us against losses which we literally cannot cover with our own money, but it also protects us against losses which set our wealth back far enough that we lose out on significant compounding effects.
> 
> To determine where the threshold for large enough losses is, we need to calculate.

#### AI Assisted Programming
[My AI Skeptic Friends Are All Nuts · The Fly Blog](https://fly.io/blog/youre-all-nuts/) #ai #software #programming 

I like the fact that the term "vibe-coding" has been used (and in an appropriate context) all of two times in the entire post. I also like the use of the term "AI-assisted programming" which is what I do most of the time.

> **Important caveat**: I’m discussing only the implications of LLMs for software development. For art, music, and writing? I got nothing. I’m inclined to believe the skeptics in those fields. I just don’t believe them about mine.

Read your AI-generated code line-by-line before merging.

> Are you a vibe coding Youtuber? Can you not read code? If so: astute point. Otherwise: what the fuck is wrong with you?
> 
> You’ve always been responsible for what you merge to `main`. You were five years go. And you are tomorrow, whether or not you use an LLM.
> 
> If you build something with an LLM that people will depend on, read the code. In fact, you’ll probably do more than that. You’ll spend 5-10 minutes knocking it back into your own style. LLMs are [showing signs of adapting](https://github.com/PatrickJS/awesome-cursorrules) to local idiom, but we’re not there yet.
> 
> People complain about LLM-generated code being “probabilistic”. No it isn’t. It’s code. It’s not Yacc output. It’s knowable. The LLM might be stochastic. But the LLM doesn’t matter. What matters is whether you can make sense of the result, and whether your guardrails hold.
> 
> Reading other people’s code is part of the job. If you can’t metabolize the boring, repetitive code an LLM generates: skills issue! How are you handling the chaos human developers turn out on a deadline?
> 
> † (because it can hold 50-70kloc in its context window)
> 
> For the last month or so, Gemini 2.5 has been my go-to †. Almost nothing it spits out for me merges without edits. I’m sure there’s a skill to getting a SOTA model to one-shot a feature-plus-merge! But I don’t care. I like moving the code around and chuckling to myself while I delete all the stupid comments. I have to read the code line-by-line anyways.

on "craft":

> Professional software developers are in the business of solving practical problems for people with code. We are not, in our day jobs, artisans. Steve Jobs was wrong: we do not need to carve the unseen feet in the sculpture. Nobody cares if the logic board traces are pleasingly routed. If anything we build endures, it won’t be because the codebase was beautiful.
> 
> Besides, that’s not really what happens. If you’re taking time carefully golfing functions down into graceful, fluent, minimal functional expressions, alarm bells should ring. You’re yak-shaving. The real work has depleted your focus. You’re not building: you’re self-soothing.
> 
> Which, wait for it, is something LLMs are good for. They devour schlep, and clear a path to the important stuff, where your judgement and values really matter.

on mediocrity

> As a mid-late career coder, I’ve come to appreciate mediocrity. You should be so lucky as to have it flowing almost effortlessly from a tap.
> 
> We all write mediocre code. Mediocre code: often fine. Not all code is equally important. Some code should be mediocre. Maximum effort on a random unit test? You’re doing something wrong. Your team lead should correct you.
> 
> Developers all love to preen about code. They worry LLMs lower the “ceiling” for quality. Maybe. But they also raise the “floor”.

hear! hear!

> To the consternation of many of my friends, I’m not a radical or a futurist. I’m a statist. I believe in the haphazard perseverance of complex systems, of institutions, of reversions to the mean. I write Go and Python code. I’m not a Kool-aid drinker.

#### New Yorker profile on Curtis Yavin
[Curtis Yarvin’s Plot Against America \| The New Yorker](https://www.newyorker.com/magazine/2025/06/09/curtis-yarvin-profile) 

> The German academic Hans-Hermann Hoppe is sometimes described as an intellectual gateway to the far right. A retired economics professor at the University of Nevada, Las Vegas, Hoppe argues that universal suffrage has supplanted rule by a “natural élite”; advocates for breaking nations into smaller, homogenous communities; and calls for communists, homosexuals, and others who oppose this rigid social order to be “physically removed.” (Some white nationalists have made memes pairing Hoppe’s face with a helicopter—an allusion to the Chilean dictator Augusto Pinochet’s practice of executing opponents by throwing them from aircraft.) Though Hoppe favors a minimal state, he believes that freedom is better preserved by monarchy than by democracy.