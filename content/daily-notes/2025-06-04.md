### 2025-06-04
#### AI is not a technology, it's an ideology
[Toolmen \| A Working Library](https://aworkinglibrary.com/writing/toolmen) #ai #ideology #technology 

> “Artificial intelligence” is not a technology. A chef’s knife is a technology, as are the practices around its use in the kitchen. A tank is a technology, as are the ways a tank is deployed in war. Both can kill, but one cannot meaningfully talk about a technology that encompasses both Sherman and santoku; the affordances, practices, and intentions are far too different to be brought into useful conversation. Likewise, in the hysterical gold rush to hoover up whatever money they can, the technocrats have labeled any and all manner of engineering practices as “AI” and riddled their products with sparkle emojis, to the extent that what we mean when we say AI is, from a technology standpoint, no longer meaningful. AI seems to be, at every moment, everything from an algorithm of the kind that has been in use for half a century, to bullshit generators that clutter up our information systems, to the promised arrival of a new consciousness—a prophesied god who will either savage us or save us or, somehow, both at the same time. There exists no coherent notion of what AI is or could be, and no meaningful effort to coalesce around a set of practices, because to do so would be to reduce the opportunity for grift.
> 
> What AI _is_ is an ideology—a system of ideas that has swept up not only the tech industry but huge parts of government on both sides of the aisle, a supermajority of everyone with assets in the millions and up, and a seemingly growing sector of the journalism class. The ideology itself is nothing new—it is the age-old system of supremacy, granting care and comfort to some while relegating others to servitude and penury—but the wrappings have been updated for the late capital, late digital age, a gaudy new cloak for today’s would-be emperors. Engaging with AI as a _technology_ is to play the fool—it’s to observe the reflective surface of the thing without taking note of the way it sends roots deep down into the ground, breaking up bedrock, poisoning the soil, reaching far and wide to capture, uproot, strangle, and steal everything within its reach. It’s to stand aboveground and pontificate about the marvels of this bright new magic, to be dazzled by all its flickering, glittering glory, its smooth mirages and six-fingered messiahs, its apparent obsequiousness in response to all your commands, right up until the point when a sinkhole opens up and swallows you whole.

#### When is Insurance Worth It
[When Is Insurance Worth It?](https://entropicthoughts.com/when-is-insurance-worth-it) #insurance #finance 

> These are the things I would say in response.
>
> - It is not a philosophical question, it is a mathematical one.
> - Technically, some insurance is worth its price, _even when_ the insurance company makes a profit.
> - Whether or not to get insurance should have nothing to do with what makes one sleep – again, it is a mathematical decision with a correct answer.
> - Saving up the premium instead of getting insurance is making the mistake of conflating an ensemble average with a time average.
> - Love does not make insurance a mathematically appropriate decision. Running the numbers does.

> The purpose if insurance is _not_ only to help us pay for things that we literally do not have enough money to pay for. It does help in that situation, but the purpose of insurance is much broader than that. What insurance does is help us avoid large drawndowns on our accumulated wealth, in order for our wealth to gather compound interest faster.
> 
> Think about that. _Even though insurance is an expected loss for the insured_, it helps us earn more money in the long run. This comes back to the [Kelly criterion](https://entropicthoughts.com/the-misunderstood-kelly-criterion.html), which teaches us that the compounding effects on wealth can make it worth paying a little up front to avoid a potential large loss later.33 The typical example is how it takes as long to go from $2,000 to $10,000 as it does from $10,000 to $50,000. This means that if we are forced to pay $8,000 out of our $10,000 wealth, we will end up with $10,000 again at the same time as we would have ended up with $50,000 if we had not been forced to pay. Losing $8,000 at one point is equal to a $40,000 loss later on, once compounding is taken into account. No wonder Einstein coined compounding the eighth wonder of the world. This effect is huge. Having to shell out 20 % of our wealth for an unexpected accident is so bad – even if the accident is improbable – that we may want to chuck out a guaranteed 0.5 % of our wealth to get out of that risk.
> 
> _This_ is the hidden purpose of insurance. It’s great at protecting us against losses which we literally cannot cover with our own money, but it also protects us against losses which set our wealth back far enough that we lose out on significant compounding effects.
> 
> To determine where the threshold for large enough losses is, we need to calculate.

#### AI Assisted Programming
[My AI Skeptic Friends Are All Nuts · The Fly Blog](https://fly.io/blog/youre-all-nuts/) #ai #software #programming 

I like the fact that the term "vibe-coding" has been used (and in an appropriate context) all of two times in the entire post. I also like the use of the term "AI-assisted programming" which is what I do most of the time.

> **Important caveat**: I’m discussing only the implications of LLMs for software development. For art, music, and writing? I got nothing. I’m inclined to believe the skeptics in those fields. I just don’t believe them about mine.

Read your AI-generated code line-by-line before merging.

> Are you a vibe coding Youtuber? Can you not read code? If so: astute point. Otherwise: what the fuck is wrong with you?
> 
> You’ve always been responsible for what you merge to `main`. You were five years go. And you are tomorrow, whether or not you use an LLM.
> 
> If you build something with an LLM that people will depend on, read the code. In fact, you’ll probably do more than that. You’ll spend 5-10 minutes knocking it back into your own style. LLMs are [showing signs of adapting](https://github.com/PatrickJS/awesome-cursorrules) to local idiom, but we’re not there yet.
> 
> People complain about LLM-generated code being “probabilistic”. No it isn’t. It’s code. It’s not Yacc output. It’s knowable. The LLM might be stochastic. But the LLM doesn’t matter. What matters is whether you can make sense of the result, and whether your guardrails hold.
> 
> Reading other people’s code is part of the job. If you can’t metabolize the boring, repetitive code an LLM generates: skills issue! How are you handling the chaos human developers turn out on a deadline?
> 
> † (because it can hold 50-70kloc in its context window)
> 
> For the last month or so, Gemini 2.5 has been my go-to †. Almost nothing it spits out for me merges without edits. I’m sure there’s a skill to getting a SOTA model to one-shot a feature-plus-merge! But I don’t care. I like moving the code around and chuckling to myself while I delete all the stupid comments. I have to read the code line-by-line anyways.

on "craft":

> Professional software developers are in the business of solving practical problems for people with code. We are not, in our day jobs, artisans. Steve Jobs was wrong: we do not need to carve the unseen feet in the sculpture. Nobody cares if the logic board traces are pleasingly routed. If anything we build endures, it won’t be because the codebase was beautiful.
> 
> Besides, that’s not really what happens. If you’re taking time carefully golfing functions down into graceful, fluent, minimal functional expressions, alarm bells should ring. You’re yak-shaving. The real work has depleted your focus. You’re not building: you’re self-soothing.
> 
> Which, wait for it, is something LLMs are good for. They devour schlep, and clear a path to the important stuff, where your judgement and values really matter.

on mediocrity

> As a mid-late career coder, I’ve come to appreciate mediocrity. You should be so lucky as to have it flowing almost effortlessly from a tap.
> 
> We all write mediocre code. Mediocre code: often fine. Not all code is equally important. Some code should be mediocre. Maximum effort on a random unit test? You’re doing something wrong. Your team lead should correct you.
> 
> Developers all love to preen about code. They worry LLMs lower the “ceiling” for quality. Maybe. But they also raise the “floor”.

hear! hear!

> To the consternation of many of my friends, I’m not a radical or a futurist. I’m a statist. I believe in the haphazard perseverance of complex systems, of institutions, of reversions to the mean. I write Go and Python code. I’m not a Kool-aid drinker.

#### New Yorker profile on Curtis Yavin
[Curtis Yarvin’s Plot Against America \| The New Yorker](https://www.newyorker.com/magazine/2025/06/09/curtis-yarvin-profile) 

> The German academic Hans-Hermann Hoppe is sometimes described as an intellectual gateway to the far right. A retired economics professor at the University of Nevada, Las Vegas, Hoppe argues that universal suffrage has supplanted rule by a “natural élite”; advocates for breaking nations into smaller, homogenous communities; and calls for communists, homosexuals, and others who oppose this rigid social order to be “physically removed.” (Some white nationalists have made memes pairing Hoppe’s face with a helicopter—an allusion to the Chilean dictator Augusto Pinochet’s practice of executing opponents by throwing them from aircraft.) Though Hoppe favors a minimal state, he believes that freedom is better preserved by monarchy than by democracy.
>
> Yarvin nearly ended up a libertarian. As a Bay Area coder and a devotee of Austrian-school economists in his late twenties, he exhibited all the risk factors. Then he discovered Hoppe’s book “[Democracy: The God That Failed](https://www.amazon.com/Democracy-Economics-Politics-Perspectives-Democratic/dp/0765808684)” (2001) and changed his mind. Yarvin soon adopted Hoppe’s imago of a benevolent strongman—someone who would govern efficiently, avoid senseless wars, and prioritize the well-being of his subjects. “It’s not copy-and-pasted, but it is such a direct influence that it’s kind of obscene,” Julian Waller, a scholar of authoritarianism at George Washington University, said. (Over e-mail, Hoppe recalled that he met Yarvin once at an exclusive gathering at Peter Thiel’s home, where Hoppe had been invited to speak. He acknowledged his influence on Yarvin, but added, “For my taste his writing has always been a bit too flowery and rambling.”) Hoppe argues that, unlike democratically elected officials, a monarch has a long-term incentive to safeguard his subjects and the state, because both belong to him. Anyone familiar with the history of dictatorships might find this idea disingenuous. Not Yarvin.

> It wasn’t until he reached the end of his speech, ten minutes later, that I realized he was, in his own way, addressing my initial question. “Unless we can totally reëngineer DNA to change what a human being is, there are many people who should not live in a modern way but in a traditional way,” he concluded. “And _that_ is a level of revolution that is so far beyond anything the Trump-Vance regime is doing.”

> …On his travels, he often hosted “office hours”—informal, freewheeling discussions with readers, many of them thoughtful young men, alienated by liberal guilt and groupthink. What wins Yarvin converts is less the soundness of his arguments than the transgressive energy they exude: he makes his listeners feel that he is granting them access to forbidden knowledge—about racial hierarchy, historical conspiracies, and the perfidy of democratic rule—that progressive culture is at pains to suppress. His approach seizes on the reality that most Americans have never learned how to defend democracy; they were simply brought up to believe in it.
> 
> Yarvin advises his followers to avoid culture-war battles over issues like D.E.I. and abortion. It is wiser, he argues, to let the democratic system collapse on its own. In the meantime, dissidents should focus on becoming “fashionable” by building a reactionary subculture—a counter-Cathedral. Sam Kriss, a left-wing writer who has debated Yarvin, said of his work, “It flatters people who believe they can change the world simply by having weird ideas on the Internet and decadent parties in Manhattan.”
> 
> Such people have come to be known as the “dissident right,” a loose constellation of artists and strivers clustered around the Bay Area, Miami, and the Lower East Side micro-neighborhood Dimes Square. The milieu was drawn together by a frustration with electoral politics, _Covid_ lockdowns, and the strictures of “wokeness.” Vice signalling has been central to the scene’s countercultural allure: instead of sharing pronouns and employing the approved nomenclature (“unhoused,” “Latinx,” “justice-involved person”), its members have revived insults like “gay” and “retarded.”

> In the past decade, liberalism has taken a beating from both sides of the political spectrum. Its critics to the left view its measured gradualism as incommensurate to the present’s multiple emergencies: climate change, inequality, the rise of an ethno-nationalist right. Conservatives, by contrast, paint liberalism as a cultural leviathan that has trampled traditional values underfoot. In “[Why Liberalism Failed](https://www.amazon.com/Why-Liberalism-Failed-Politics-Culture/dp/0300223447)” (2018), the Notre Dame political scientist Patrick Deneen argues that the contemporary American emphasis on individual freedom has come at the expense of family, faith, and community, turning us into “increasingly separate, autonomous, non-relational selves replete with rights and defined by our liberty, but insecure, powerless, afraid, and alone.” Other post-liberal theorists, including Adrian Vermeule, have proposed that the state curtail certain rights in the service of an explicitly Catholic “common good.”
> 
> Yarvin is calling for something simpler and more libidinally satisfying: to burn it all down and start again from scratch. Since the advent of neoliberalism in the late seventies, political leaders have increasingly treated governance like corporate management, turning citizens into customers and privatizing services. The result has been greater inequality, a weakened social safety net, and the widespread perception that democracy itself is to blame for these ills, creating an appetite for exactly the kind of autocratic efficiency Yarvin now extolls. “A Yarvin program might seem seductive during a period of neoliberal rule, where efforts to change things, whether it is global warming or the war machine, feel futile,” the historian Suzanne Schneider told me. “You can sit back, not give a fuck, and let someone else run the show.” Yarvin has little to say on the question of human flourishing, or about humans in general, who appear in his work as sheep to be herded, idiots to be corrected, or marionettes controlled by leftist puppeteers.

#### Dwarkesh on AI Progress
[Why I have slightly longer timelines than some of my guests](https://www.dwarkesh.com/p/timelines-june-2025) #ai #learning 


> But the fundamental problem is that LLMs don’t get better over time the way a human would. The lack of continual learning is a huge huge problem. The LLM baseline at many tasks might be higher than an average human's. But there’s no way to give a model high level feedback. You’re stuck with the abilities you get out of the box. You can keep messing around with the system prompt. In practice this just doesn’t produce anything even close to the kind of learning and improvement that human employees experience.


> While this makes me bearish on transformative AI in the next few years, it makes me especially bullish on AI over the next decades. When we do solve continuous learning, we’ll see a huge discontinuity in the value of the models. Even if there isn’t a software only singularity (with models rapidly building smarter and smarter successor systems), we might still see something that looks like a broadly deployed intelligence explosion. AIs will be getting broadly deployed through the economy, doing different jobs and learning while doing them in the way humans can. But unlike humans, these models can amalgamate their learnings across all their copies. So one AI is basically learning how to do every single job in the world. **An AI that is capable of online learning might functionally become a superintelligence quite rapidly without any further algorithmic progrss**