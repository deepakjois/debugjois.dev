### 2025-05-07
#### Alternate Coffee Varieties
[The resilient coffee discovery that could save our morning brew](https://on.ft.com/3SncKkP) #coffee #stenophylla

> While one solution is to shift production geographically as the climate changes, people like Davis, head of coffee research at Kew, and longtime collaborator Jeremy Haggar of the University of Greenwich, think a more sustainable answer is to diversify into climate-resilient choices among the 131 coffee species identified so far. 
> 
> The two most exciting new species on the block, Davis told me, are excelsa and stenophylla. Excelsa has a deeper root system, allowing access to water in drought conditions, and is also resistant to heat, pests and disease. The first coffee from a Ugandan excelsa project that he has been involved in will come to the UK market this year (he reports the smooth taste to be comparable to a speciality arabica).
> 
> Stenophylla is at a more experimental stage. In 2018, Davis and Haggar managed to track down the plant in Sierra Leone with the help of Daniel Sarmu, a coffee specialist in the country. Together with the coffee company Sucafina, the NGO Welthungerhilfe and the co-operation of local communities, the trio have planted wild varieties in trial plots across Sierra Leone with a view to reviving it as a coffee crop (its prospects withered in the mid-20th century as local farmers turned to robusta). The first harvest is expected this year.

#### Podcast Bros and Brain Rot
[Podcast Bros and Brain Rot - Nathan Cofnas’s Newsletter](https://ncofnas.com/p/podcast-bros-and-brain-rot) #brainrot #podcasts #social-media 

> People who don’t trust “experts” now look to podcasters and other alt-media figures—many of whom (including Rogan and Brand) are comedians—to decide what to believe about everything from WWII to vaccines to Ukraine to tariffs. The result has been a proliferation of ignorance with disastrous consequences for our culture and public policy.
> 
> Uneducated podcast bros have not found a magic shortcut to knowledge. Even on Covid, they have _not_ outperformed actual experts. However, it’s true that many so-called experts are fake and/or corrupt. Blind obedience to credentialed authority (associated with the left) or trust in a “marketplace of ideas” that rewards brain-rotting infotainment (associated with the right) are both failed strategies.

#### Matt Levine on Memecoins
[OpenAI Will Get A Bit More Normal - Bloomberg](https://www.bloomberg.com/opinion/newsletters/2025-05-06/openai-will-get-a-bit-more-normal?cmpid=BBD050625_MONEYSTUFF&sref=6rqLu4ZS) #memecoin #crypto 

> [The point of a memecoin](https://links.message.bloomberg.com/s/c/BtEcnslqR93CsOLw9Nb21cziyHXK7RMLh6et1qSRHGMySLe9nDE4hzI8hbO1H6IU18keDQiFW_1rlky9Y-v26u8jwp8YJfmv1qfhA-VEpR50-7M1mRXNg4GtTyEIX9ztKL_OyQfowohYZiZqgDLducUxSIMI2Y0Fcdcs23eCRr0Ew-MAb5PnLU8wdVnkKR7qt6geHCkla9uTZiZlpiEphpCCo2LatF0UTsfzEmWGvh010qZ89cvNAvgo67LPIUvdb_cbAKUWnrq4RbY_wgoMknVLA1_0duRPDU4dl0w0w1gtWKsXbP-nlPrL077z6DWp3ASy1IoO0sL_1gaJerfIYNaFOhJbFkz3-pn6agI2zn3o1LCgXFTDe8-BIY0/ryr5pOk4c0NtygvpXkA72MaJhGSOEkPz/8) is that for 15 minutes everyone in crypto coordinates to (1) pay attention to some person and (2) turn that attention into money by buying a token. And then they move on. I don’t know why this is a fun game for anyone to play, but apparently it is. In this game, somebody is going to make money by buying the token at the beginning of the 15 minutes, and somebody else is going to lose money by buying it at the end of the 15 minutes. There is not a different thing that can happen; the memecoin is not going to build enduring value and steady cash flows. It is going to go up while people are briefly paying attention, and then it is going to go down when they stop. Perhaps you can get people to pay attention more than once, but that is just repeating the same process; it’s not building enduring value.
> 
> Oh now obviously if people buy the coin before its public announcement, they will do even better than the people who buy it right after the public announcement. And one can guess that those people are insiders who are connected with the promoters of the memecoin. But of course those are the people who will make money! It’s their meme! You are paying money to buy a token representing “I paid attention to Melania Trump today.” Who should get that money, if not Melania Trump or whoever set up the coin for her?

#### The enshittification of tech jobs
[Pluralistic: The enshittification of tech jobs (27 Apr 2025) – Pluralistic: Daily links from Cory Doctorow](https://pluralistic.net/2025/04/27/some-animals/#are-more-equal-than-others) #tech #jobs #enshittification

Cory Doctorow is a really gifted writer. Love the concept of Vocational Awe in the paragraph 

> Tech workers are a weird choice for "princes of labor," but for decades they've enjoyed unparalleled labor power, expressed in high wages, lavish stock grants, and whimsical campuses with free laundry and dry-cleaning, gourmet cafeterias, and kombucha on tap:
> 
> [https://www.youtube.com/watch?v=nhUtdgVZ7MY](https://www.youtube.com/watch?v=nhUtdgVZ7MY)
> 
> All of this, despite the fact that tech union density is so low it can barely be charted. Tech workers' power didn't come from solidarity, it came from scarcity. When you're getting five new recruiter emails every day, you don't need a shop steward to tell your boss to go fuck themselves at the morning scrum. You can do it yourself, secure in the knowledge that there's a company across the road who'll give you a better job by lunchtime.
> 
> Tech bosses sucked up to their workers because tech workers are _insanely_ productive. Even with sky-high salaries, every hour a tech worker puts in on the job translates into massive profits. Which created a conundrum for tech bosses: if tech workers produce incalculable value for the company every time they touch their keyboards, and if there aren't enough tech workers to go around, how do you get whichever tech workers you can hire to put in as many hours as possible?
> 
> The answer is a tactic that Fobazi Ettarh called "vocational awe":
> 
> [https://www.inthelibrarywiththeleadpipe.org/2018/vocational-awe/](https://www.inthelibrarywiththeleadpipe.org/2018/vocational-awe/)
> 
> "Vocational awe" describes the feeling that your work matters so much that you should accept all manner of tradeoffs and calamities to get the job done. Ettarh uses the term to describe the pathology of librarians, teachers, nurses and other underpaid, easily exploited workers in "caring professions." Tech workers are weird candidates for vocational awe, given how well-paid they are, but never let it be said that tech bosses don't know how to innovate – they successfully transposed an exploitation tactic from the most precarious professionals to the _least_ precarious.
> 
> As farcical as all the engineer-pampering tech bosses got up to for the first couple decades of this century was, it certainly paid off. Tech workers stayed at the office for every hour that god sent, skipping their parents' funerals and their kids' graduations to ship on time. Snark all you like about empty platitudes like "organize the world's information and make it useful" or "bring the world closer together," but you can't argue with results: workers who could – and did – bargain for _anything_ from their bosses…_except_ a 40-hour work-week.
> 
> But for tech bosses, this vocational awe wheeze had a fatal flaw: if you convince your workforce that they are monk-warriors engaged in the holy labor of bringing forth a new, better technological age, they aren't going to be very happy when you order them to enshittify the products they ruined their lives to ship. "I fight for the user" has been lurking in the hindbrains of so many tech workers since the _Tron_ years, somehow nestling comfortably alongside of the idea that "I don't need a union, I'm a temporarily embarrassed founder."

About the narrative of AI vs reality of AI

> Bindley spoke to David Markley, an Amazon veteran turned executive coach, who attributed the worsening conditions (for example, managers being given 30 direct reports) to the "narrative" of AI. Not, you'll note, the _actual reality_ of AI, but rather, the _story_ that AI lets you "collapse the organization," slash headcount and salaries, and pauperize the (former) princes of labor.
> 
> The point of AI isn't to make workers more productive, it's to make them weaker when they bargain with their bosses. Another of Bindley's sources went through _eight rounds_ of interviews with a company, received an offer, countered with a request for 12% more than the offer, and had the job withdrawn, because "the company didn’t want to move ahead anymore based on the way the compensation conversation had gone."

#### Arvind Narayanan on Avoiding Risks with Generative AI
[https://x.com/random\_walker/status/1919359709062033850](https://x.com/random_walker/status/1919359709062033850)  #ai #risks

> When we use generative AI for work, there are two ever-present risks: hallucinations/confabulations and deskilling. For each of my AI use cases, I try to make sure I know how I'm avoiding those risks. Specifically:
> 
> * AI is helpful despite being error-prone if it is faster to verify the output than it is to do the work yourself. For example, if you're using it to find a product that matches a given set of specifications, verification may be a lot faster than search.
> 
> * There are many uses where errors don't matter, like using it to enhance creativity by suggesting or critiquing ideas.
> 
> * At a meta level, if you use AI without a plan and simply turn to AI tools when you feel like it, then you're unlikely to be able to think through risks and mitigations. It is better to identify concrete ways to integrate AI into your workflows, with known benefits and risks, that you can employ repeatedly.
> 
> * Turning to deskilling, in some cases the worries are overblown. We should distinguish between essential skills and incidental skills for each job. Incidental skills are those that it's okay to delegate to automation as long as people understand the underlying principles. For example, back in the day when programming languages and compilers were developed, there were worries about people losing the ability to directly write machine code, but that proved unfounded.
> 
> * On the other hand, if a junior developer relies too much on vibe coding and hence can't program at all by themselves, in any language, and doesn't understand the principles of programming, that definitely feels like a problem.
> 
> * Deskilling is usually discussed in the context of junior workers but I think it's a problem at any career stage. Even setting aside AI, there are many senior people who stop learning and have an ossified set of skills.
> 
> * Deskilling is a much more insidious problem than errors, because it happens gradually over years, so you may never notice.
> 
> * I think the way to address it is structural, and not even AI-specific. If you're always scrambling to meet a deadline, there will be too much temptation to take shortcuts (including, but not limited to, overuse of AI), and your skills will atrophy.
> 
> * My own strategy is to set aside about one day a week, sometimes more, for activities that are more about learning and growth than about productivity. This comes at a huge short-term cost but I think it is necessary in the long run.
> 
> * Depending on the job and task, there are other potential risks from AI. Having a plan to address errors and deskilling is necessary, but not sufficient, to ensure a beneficial approach to AI.

#### The Solution Problem
A great series of essays which in a long-winded but very thoughtful and insightful way tries to explain why the mental health landscape is pretty bad nowadays.

* [The Solution Problem (Part 1/3) - by Josh Zlatkus](https://thelivingfossils.substack.com/p/the-solution-problem-part-13)
* [The Solution Problem (Part 2/3) - by Josh Zlatkus](https://thelivingfossils.substack.com/p/the-solution-problem-part-23)
* [The Solution Problem (Part 3/3) - by Josh Zlatkus](https://thelivingfossils.substack.com/p/the-solution-problem-part-33)